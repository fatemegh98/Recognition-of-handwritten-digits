{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hoda_cdb(file_name):\n",
    "    with open(file_name, 'rb') as binary_file:\n",
    "\n",
    "        data = binary_file.read()\n",
    "\n",
    "        offset = 0\n",
    "\n",
    "        # read private header\n",
    "\n",
    "        yy = struct.unpack_from('H', data, offset)[0]\n",
    "        offset += 2\n",
    "\n",
    "        m = struct.unpack_from('B', data, offset)[0]\n",
    "        offset += 1\n",
    "\n",
    "        d = struct.unpack_from('B', data, offset)[0]\n",
    "        offset += 1\n",
    "\n",
    "        H = struct.unpack_from('B', data, offset)[0]\n",
    "        offset += 1\n",
    "\n",
    "        W = struct.unpack_from('B', data, offset)[0]\n",
    "        offset += 1\n",
    "\n",
    "        TotalRec = struct.unpack_from('I', data, offset)[0]\n",
    "        offset += 4\n",
    "\n",
    "        LetterCount = struct.unpack_from('128I', data, offset)\n",
    "        offset += 128 * 4\n",
    "\n",
    "        imgType = struct.unpack_from('B', data, offset)[0]  # 0: binary, 1: gray\n",
    "        offset += 1\n",
    "\n",
    "        Comments = struct.unpack_from('256c', data, offset)\n",
    "        offset += 256 * 1\n",
    "\n",
    "        Reserved = struct.unpack_from('245c', data, offset)\n",
    "        offset += 245 * 1\n",
    "\n",
    "        if (W > 0) and (H > 0):\n",
    "            normal = True\n",
    "        else:\n",
    "            normal = False\n",
    "\n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        for i in range(TotalRec):\n",
    "\n",
    "            StartByte = struct.unpack_from('B', data, offset)[0]  # must be 0xff\n",
    "            offset += 1\n",
    "\n",
    "            label = struct.unpack_from('B', data, offset)[0]\n",
    "            offset += 1\n",
    "\n",
    "            if not normal:\n",
    "                W = struct.unpack_from('B', data, offset)[0]\n",
    "                offset += 1\n",
    "\n",
    "                H = struct.unpack_from('B', data, offset)[0]\n",
    "                offset += 1\n",
    "\n",
    "            ByteCount = struct.unpack_from('H', data, offset)[0]\n",
    "            offset += 2\n",
    "\n",
    "            image = np.zeros(shape=[H, W], dtype=np.uint8)\n",
    "\n",
    "            if imgType == 0:\n",
    "                # Binary\n",
    "                for y in range(H):\n",
    "                    bWhite = True\n",
    "                    counter = 0\n",
    "                    while counter < W:\n",
    "                        WBcount = struct.unpack_from('B', data, offset)[0]\n",
    "                        offset += 1\n",
    "                        # x = 0\n",
    "                        # while x < WBcount:\n",
    "                        #     if bWhite:\n",
    "                        #         image[y, x + counter] = 0  # Background\n",
    "                        #     else:\n",
    "                        #         image[y, x + counter] = 255  # ForeGround\n",
    "                        #     x += 1\n",
    "                        if bWhite:\n",
    "                            image[y, counter:counter + WBcount] = 0  # Background\n",
    "                        else:\n",
    "                            image[y, counter:counter + WBcount] = 255  # ForeGround\n",
    "                        bWhite = not bWhite  # black white black white ...\n",
    "                        counter += WBcount\n",
    "            else:\n",
    "                # GrayScale mode\n",
    "                data = struct.unpack_from('{}B'.format(W * H), data, offset)\n",
    "                offset += W * H\n",
    "                image = np.asarray(data, dtype=np.uint8).reshape([W, H]).T\n",
    "\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "\n",
    "        return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images,labels = read_hoda_cdb('Train 60000.cdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27ac577bbe0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(images[4].shape)\n",
    "plt.imshow(images[4],cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change image shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_images = []\n",
    "for i in range(len(images)):\n",
    "    img = images[i]\n",
    "    if img.shape[0]%3 == 2 :\n",
    "        arr = np.zeros(img.shape[1])\n",
    "        img = np.vstack((img,arr))\n",
    "    if img.shape[0]%3 == 1 :\n",
    "        arr = np.zeros(img.shape[1])\n",
    "        img = np.vstack((img,arr))\n",
    "        img = np.vstack((img,arr))\n",
    "    if img.shape[1]%3 == 2 :\n",
    "        arr = np.zeros((img.shape[0],1))\n",
    "        img = np.hstack((img,arr))\n",
    "    if img.shape[1]%3 == 1 :\n",
    "        arr = np.zeros((img.shape[0],1))\n",
    "        img = np.hstack((img,arr))\n",
    "        img = np.hstack((img,arr))\n",
    "    new_images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(new_images)):\n",
    "    if new_images[i].shape[0]%3 != 0:\n",
    "        print('no')\n",
    "    if new_images[i].shape[1]%3 != 0:\n",
    "        print('no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# canny operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "newnew_images = []\n",
    "for i in range(len(new_images)):\n",
    "    img = np.uint8(new_images[i])\n",
    "    edges = cv.Canny(img,100,200)\n",
    "    newnew_images.append(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# devide each image to nine equal part and computing chain code histogram for each part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image_parts = []\n",
    "img_feature = np.zeros((len(newnew_images),72))\n",
    "\n",
    "for t in range(len(newnew_images)):\n",
    "    im = Image.fromarray(newnew_images[t])\n",
    "    imgwidth, imgheight = im.size\n",
    "    height = int(imgheight/3)\n",
    "    width = int(imgwidth/3)\n",
    "    list_part = []\n",
    "    for i in range(0,imgheight,height):\n",
    "        for j in range(0,imgwidth,width):\n",
    "            box = (j, i, j+width, i+height)\n",
    "            a = im.crop(box)\n",
    "            list_part.append(a)\n",
    "    part_feature = np.zeros((9,8))      \n",
    "    for h in range(len(list_part)):\n",
    "        if np.mean(np.asarray(list_part[h])) == 0:\n",
    "            part_feature[h,:] = [0,0,0,0,0,0,0,0]\n",
    "        else:\n",
    "            codes = fenc.encode_freeman(np.asarray(list_part[h]))\n",
    "        one_count = 0\n",
    "        two_count = 0\n",
    "        three_count = 0\n",
    "        four_count = 0\n",
    "        five_count = 0\n",
    "        six_count = 0\n",
    "        seven_count = 0\n",
    "        zero_count = 0\n",
    "        for z in range(len(codes)):\n",
    "            num = int(codes[z])\n",
    "            if num ==0:\n",
    "                zero_count+=1\n",
    "            elif num==1:\n",
    "                one_count+=1\n",
    "            elif num==2:\n",
    "                two_count+=1\n",
    "            elif num == 3:\n",
    "                three_count+=1\n",
    "            elif num == 4:\n",
    "                four_count+=1\n",
    "            elif num ==5:\n",
    "                five_count+=1\n",
    "            elif num==6:\n",
    "                six_count+=1\n",
    "            elif num==7:\n",
    "                seven_count+=1\n",
    "        part_feature[h,:] = [zero_count/(len(codes)+1),one_count/(len(codes)+1),two_count/(len(codes)+1),three_count/(len(codes)+1),four_count/(len(codes)+1),five_count/(len(codes)+1),six_count/(len(codes)+1),seven_count/(len(codes)+1)]\n",
    "    part_feature = part_feature.ravel(order='C')\n",
    "    img_feature[t,:] = part_feature\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_parts = np.zeros((len(newnew_images),9))\n",
    "my_list\n",
    "\n",
    "part_img = np.zeros(9)\n",
    "for i in range(len(image_parts)):\n",
    "    for j in range(9):\n",
    "        part_img[j] = image_parts[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3)\n",
    "fig.set_size_inches(8,6)\n",
    "axes[0,0].imshow(image_parts[0], cmap=plt.cm.gray)\n",
    "axes[0,1].imshow(image_parts[1], cmap=plt.cm.gray)\n",
    "axes[0,2].imshow(image_parts[2], cmap=plt.cm.gray)\n",
    "axes[1,0].imshow(image_parts[3], cmap=plt.cm.gray)\n",
    "axes[1,1].imshow(image_parts[4], cmap=plt.cm.gray)\n",
    "axes[1,2].imshow(image_parts[5], cmap=plt.cm.gray)\n",
    "axes[2,0].imshow(image_parts[6], cmap=plt.cm.gray)\n",
    "axes[2,1].imshow(image_parts[7], cmap=plt.cm.gray)\n",
    "axes[2,2].imshow(image_parts[8], cmap=plt.cm.gray)\n",
    "for ax in axes.ravel():\n",
    "    ax.set_axis_off()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import math\n",
    "from skimage import measure\n",
    "from copy import deepcopy, copy\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class FreemanEncoder(object):\n",
    "    '''\n",
    "    classdocs\n",
    "    '''\n",
    "    #Class global variables\n",
    "    #WATCH_OUT! The +x is right, but +y is down, so the representation is different from normal quadrants \n",
    "#     FREEMAN_DICT = {-90:'0', -45:'1', 0:'2', 45:'3', 90:'4', 135:'5', 180:'6', -135:'7'}\n",
    "    FREEMAN_DICT = {-90:'4', -45:'3', 0:'2', 45:'1', 90:'0', 135:'7', 180:'6', -135:'5'}\n",
    "    ALLOWED_DIRECTIONS = numpy.array([0, 45, 90, 135, 180, -45, -90, -135])\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Constructor\n",
    "        '''\n",
    "        \n",
    "    def find_nearest(self, array, value):\n",
    "        '''\n",
    "        Find the nearest element of array to the given value\n",
    "        '''\n",
    "        idx = (numpy.abs(array-value)).argmin()\n",
    "        return array[idx]\n",
    "    \n",
    "    def encode_freeman(self, image_array):\n",
    "        '''\n",
    "        Encode the image contour in an 8-direction freeman chain code based on angles\n",
    "        '''\n",
    "        image_copy = copy(image_array)\n",
    "        image_contour = self.get_contours(image_copy)\n",
    "        freeman_code = \"\"\n",
    "        \n",
    "        for i in range(len(image_contour) - 1):\n",
    "            delta_x = image_contour[i+1][0] - image_contour[i][0] \n",
    "            delta_y = image_contour[i+1][1] - image_contour[i][1]\n",
    "            angle = math.degrees(math.atan2(delta_y,delta_x))\n",
    "            angle = self.find_nearest(self.ALLOWED_DIRECTIONS, angle)\n",
    "            \n",
    "#             if not(delta_x == 0 and delta_y == 0):\n",
    "#                 freeman_code += self.FREEMAN_DICT[angle]\n",
    "                \n",
    "            if delta_x == 0 and delta_y == 0:\n",
    "                pass\n",
    "            elif delta_x > 0 and delta_y == 0:\n",
    "                freeman_code += '2'\n",
    "            elif delta_x < 0 and delta_y == 0:\n",
    "                freeman_code += '6'\n",
    "            elif delta_x == 0 and delta_y > 0:\n",
    "                freeman_code += '4'\n",
    "            elif delta_x == 0 and delta_y < 0:\n",
    "                freeman_code += '0'\n",
    "            elif delta_x > 0 and delta_y > 0:\n",
    "                freeman_code += '3'\n",
    "            elif delta_x > 0 and delta_y < 0:\n",
    "                freeman_code += '1'\n",
    "            elif delta_x < 0 and delta_y > 0:\n",
    "                freeman_code += '5'\n",
    "            elif delta_x < 0 and delta_y < 0:\n",
    "                freeman_code += '7'    \n",
    "                \n",
    "#             # normalize the code\n",
    "#             freeman_code = self.normalize_freemancode(freeman_code)\n",
    "#         print freeman_code\n",
    "#         print image_contour[0],image_contour[1],image_contour[2] \n",
    "#         plt.imshow(image_array)\n",
    "#         plt.show()\n",
    "        \n",
    "        return freeman_code\n",
    "    \n",
    "    def get_contours(self, image_array):\n",
    "        #Extract the longest contour in the image\n",
    "        contours, hierarchy = cv2.findContours(image_array,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "        \n",
    "#         contours = measure.find_contours(image_array, 0.9, positive_orientation='high')\n",
    "        contours_main = max(contours, key=len)\n",
    "        contours_main = [item for sublist in contours_main for item in sublist] #only for the v2 method\n",
    "        \n",
    "        return contours_main\n",
    "    \n",
    "    def encode_freeman_dataset(self, images_dataset):\n",
    "        '''\n",
    "        Encode images dataset (given as a dictionary where keys are classes, \n",
    "        and values are the arrays of images, into a freeman code dictionary of \n",
    "        the same structure\n",
    "        '''\n",
    "        freeman_code_dict = dict((key, []) for key in images_dataset.keys())\n",
    "        for key in images_dataset:\n",
    "            for image in images_dataset[key]:\n",
    "                image_freeman = self.encode_freeman(image)\n",
    "                freeman_code_dict[key].append(image_freeman)\n",
    "                \n",
    "        return freeman_code_dict\n",
    "#         return self.pad_codes(freeman_code_dict)\n",
    "    \n",
    "    def count_bagofwords(self, string, bagofwords=set(FREEMAN_DICT.values())):\n",
    "        bagofwords_count = []\n",
    "        for char in bagofwords:\n",
    "            char_count = string.count(char)\n",
    "            bagofwords_count.append(char_count)\n",
    "            \n",
    "        return bagofwords_count\n",
    "    \n",
    "    def gen_bagofwords_dict(self, freeman_code_dict):\n",
    "        bagofwords_dict = dict((key, []) for key in freeman_code_dict.keys())\n",
    "        for key in freeman_code_dict:\n",
    "            for code in freeman_code_dict[key]:\n",
    "                code_bagofwords_count = self.count_bagofwords(code)\n",
    "                bagofwords_dict[key].append(code_bagofwords_count)\n",
    "                \n",
    "        return bagofwords_dict\n",
    "    \n",
    "    def normalize_freemancode(self,code):\n",
    "        min_code = min(code)\n",
    "        while code[0] != min_code:\n",
    "            code = code[1:] + code[:1]\n",
    "         \n",
    "\n",
    "        return code\n",
    "    \n",
    "    def pad_codes(self, codes_dict):\n",
    "        max_len = max(map(len,codes_dict.values()))\n",
    "        \n",
    "        padded_codes_dict = deepcopy(codes_dict)\n",
    "        for key in codes_dict:\n",
    "            codes = [x.zfill(max_len) for x in codes_dict[key]]\n",
    "            padded_codes_dict[key] = codes\n",
    "            \n",
    "        return padded_codes_dict\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add relative feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_features = np.zeros((len(images)))\n",
    "for i in range(len(images)):\n",
    "    img = images[i]\n",
    "    relative_feature = (img.shape[0]*img.shape[1])/2000\n",
    "    relative_features[i] = relative_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ff = img_feature\n",
    "new_img_feature= np.hstack((img_ff,relative_features.reshape(60000,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 73)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_img_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add white-black transition feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_v1 = np.zeros((len(images)))\n",
    "for i in range(len(images)):\n",
    "    img = images[i]\n",
    "    counter = 0\n",
    "    for y in range(img.shape[1]):\n",
    "        for t in range(img.shape[0]):\n",
    "            if img[t,y]==0:\n",
    "                counter +=1\n",
    "            else:\n",
    "                break\n",
    "    tr_v1[i] = counter/(img.shape[0]*img.shape[1])\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 74)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_img_feature = np.hstack((new_img_feature,tr_v1.reshape(60000,1)))\n",
    "new_img_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_h1 = np.zeros((len(images)))\n",
    "tr_h2 = np.zeros((len(images)))\n",
    "\n",
    "for i in range(len(images)):\n",
    "    img = images[i]\n",
    "    first_half = img[0:int(img.shape[0]/2),:]\n",
    "    second_half = img[int(img.shape[0]/2):,:]\n",
    "    counter_h1 = 0\n",
    "    counter_h2 = 0\n",
    "    \n",
    "    for t in range(first_half.shape[0]):\n",
    "        for y in range(first_half.shape[1]):\n",
    "            if first_half[t,y]==0:\n",
    "                counter_h1 +=1\n",
    "            else:\n",
    "                break\n",
    "    tr_h1[i] = counter_h1/(int(img.shape[0]/2)*img.shape[1])\n",
    "    \n",
    "    for t in range(second_half.shape[0]):\n",
    "        for y in range(second_half.shape[1]):\n",
    "            if second_half[t,y]==0:\n",
    "                counter_h2 +=1\n",
    "            else:\n",
    "                break\n",
    "    tr_h2[i] = counter_h2/(int(img.shape[0]/2)*img.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 76)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_img_feature= np.hstack((new_img_feature,tr_h1.reshape(60000,1)))\n",
    "new_img_feature= np.hstack((new_img_feature,tr_h2.reshape(60000,1)))\n",
    "new_img_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import skeletonize\n",
    "from skimage import data\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.util import invert\n",
    "\n",
    "skeletons = []\n",
    "for i in range(len(images)):\n",
    "    img = images[i]\n",
    "    img = img.clip(max=1)\n",
    "    # perform skeletonization\n",
    "    skeleton = skeletonize(img)\n",
    "    skeletons.append(skeleton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_v2 = np.zeros((len(skeletons)))\n",
    "for i in range(len(skeletons)):\n",
    "    img = skeletons[i]\n",
    "    counter = 0\n",
    "    transotion_num = 0\n",
    "    for y in range(img.shape[1]):\n",
    "        for t in range(img.shape[0]):\n",
    "            if img[t,y]==0:\n",
    "                counter +=1\n",
    "            elif img[t,y]==1 :\n",
    "                transotion_num+=1\n",
    "                counter +=1\n",
    "            elif transotion_num==2:\n",
    "                break\n",
    "    tr_v2[i] = counter/(img.shape[0]*img.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_v3 = np.zeros((len(skeletons)))\n",
    "for i in range(len(skeletons)):\n",
    "    img = skeletons[i]\n",
    "    counter = 0\n",
    "    transotion_num = 0\n",
    "    for y in range(img.shape[1]):\n",
    "        for t in range(img.shape[0]):\n",
    "            if img[t,y]==0:\n",
    "                counter +=1\n",
    "            elif img[t,y]==1 :\n",
    "                transotion_num+=1\n",
    "                counter +=1\n",
    "            elif transotion_num==3:\n",
    "                break\n",
    "    tr_v3[i] = counter/(img.shape[0]*img.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 78)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_img_feature= np.hstack((new_img_feature,tr_v2.reshape(60000,1)))\n",
    "new_img_feature= np.hstack((new_img_feature,tr_v3.reshape(60000,1)))\n",
    "new_img_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_h12 = np.zeros((len(images)))\n",
    "tr_h22 = np.zeros((len(images)))\n",
    "\n",
    "for i in range(len(images)):\n",
    "    img = images[i]\n",
    "    first_half = img[0:int(img.shape[0]/2),:]\n",
    "    second_half = img[int(img.shape[0]/2):,:]\n",
    "    \n",
    "    counter_h1 = 0\n",
    "    transition_num = 0\n",
    "    for t in range(first_half.shape[0]):\n",
    "        for y in range(first_half.shape[1]):\n",
    "            if first_half[t,y]==0:\n",
    "                counter_h1 +=1\n",
    "            elif first_half[t,y]==1 :\n",
    "                counter_h1 +=1\n",
    "                transition_num +=1\n",
    "            elif transition_num==2:\n",
    "                break\n",
    "    tr_h12[i] = counter_h1/(int(img.shape[0]/2)*img.shape[1])\n",
    "    \n",
    "    counter_h2 = 0\n",
    "    transition_num_1 = 0\n",
    "    for t in range(second_half.shape[0]):\n",
    "        for y in range(second_half.shape[1]):\n",
    "            if second_half[t,y]==0:\n",
    "                counter_h2 +=1\n",
    "            elif second_half[t,y]==1:\n",
    "                counter_h2 +=1\n",
    "                transition_num_1+=1\n",
    "            elif transition_num_1==2:\n",
    "                break\n",
    "    tr_h22[i] = counter_h2/(int(img.shape[0]/2)*img.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 80)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_img_feature= np.hstack((new_img_feature,tr_h12.reshape(60000,1)))\n",
    "new_img_feature= np.hstack((new_img_feature,tr_h22.reshape(60000,1)))\n",
    "new_img_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_h12 = np.zeros((len(images)))\n",
    "tr_h22 = np.zeros((len(images)))\n",
    "\n",
    "for i in range(len(images)):\n",
    "    img = images[i]\n",
    "    first_half = img[0:int(img.shape[0]/2),:]\n",
    "    second_half = img[int(img.shape[0]/2):,:]\n",
    "    \n",
    "    counter_h1 = 0\n",
    "    transition_num = 0\n",
    "    for t in range(first_half.shape[0]):\n",
    "        for y in range(first_half.shape[1]):\n",
    "            if first_half[t,y]==0:\n",
    "                counter_h1 +=1\n",
    "            elif first_half[t,y]==1 :\n",
    "                counter_h1 +=1\n",
    "                transition_num +=1\n",
    "            elif transition_num==3:\n",
    "                break\n",
    "    tr_h12[i] = counter_h1/(int(img.shape[0]/2)*img.shape[1])\n",
    "    \n",
    "    counter_h2 = 0\n",
    "    transition_num_1 = 0\n",
    "    for t in range(second_half.shape[0]):\n",
    "        for y in range(second_half.shape[1]):\n",
    "            if second_half[t,y]==0:\n",
    "                counter_h2 +=1\n",
    "            elif second_half[t,y]==1:\n",
    "                counter_h2 +=1\n",
    "                transition_num_1+=1\n",
    "            elif transition_num_1==3:\n",
    "                break\n",
    "    tr_h22[i] = counter_h2/(int(img.shape[0]/2)*img.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 82)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_img_feature= np.hstack((new_img_feature,tr_h12.reshape(60000,1)))\n",
    "new_img_feature= np.hstack((new_img_feature,tr_h22.reshape(60000,1)))\n",
    "new_img_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without transition feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9731"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = svm.SVC(C=100,kernel ='rbf', gamma=1)\n",
    "clf.fit(img_feature[:50000,:], labels[:50000])\n",
    "pred = clf.predict(img_feature[50000:,:])\n",
    "accuracy_score(labels[50000:], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with transition feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9785"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(C=100,kernel ='rbf', gamma=1)\n",
    "clf.fit(new_img_feature[:50000,:], labels[:50000])\n",
    "pred = clf.predict(new_img_feature[50000:,:])\n",
    "accuracy_score(labels[50000:], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9814"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with all transition feature\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(C=100,kernel ='rbf', gamma=1)\n",
    "clf.fit(new_img_feature[:50000,:], labels[:50000])\n",
    "pred = clf.predict(new_img_feature[50000:,:])\n",
    "accuracy_score(labels[50000:], pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
